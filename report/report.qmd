---
title: "BIOS611 Clustering Homework"
format: html
execute:
  echo: true
  warning: false
---

# Task 1 — Hypercube Clusters, K-means, and the Gap Statistic

## Objective
Evaluate how accurately the Gap Statistic (with Tibshirani’s selection rule) recovers the true number of clusters in synthetic **hypercube** datasets as the **inter-cluster separation** (edge length *L*) decreases and the **dimension** *n* varies.

## Data Generation
For each dimension \( n \in \{6,5,4,3,2\} \), we construct a hypercube in \(\mathbb{R}^n\) whose vertices are at coordinates \(\{0, L\}^n\). Each vertex is treated as a true cluster center. The true number of clusters is therefore \(K_{\text{true}} = 2^n\). Around each center, we sample points from an **isotropic Gaussian**:
\[
X \sim \mathcal{N}(\mu, \sigma^2 I_n), \quad \sigma = 1.0,
\]
with **100 points per cluster**. For each \(n\), we sweep the edge length \(L\) from 10 down to 1 (step 1), which gradually reduces inter-cluster separation.

## Clustering + Model Selection
For each dataset \((n, L)\), we run **K-means** with `nstart = 20` and `iter.max = 50`. To estimate the number of clusters \( \hat{k} \), we apply the **Gap Statistic** (R `cluster::clusGap`) with:
- Reference bootstrap samples: **B = 50** (balanced for stability and runtime).
- Upper cap for search: \(K_{\max} = \min(2^n + 3, 12)\).

**Selection rule (Tibshirani et al.)**: choose the smallest \(k\) such that
\[
\text{Gap}(k) \ge \text{Gap}(k+1) - \text{SE}(k+1).
\]

## Outputs
- **Summary table**: `results/tables/t1_gap_summary.csv` (columns: `n`, `side_length`, `K_true`, `k_hat`, etc.).
- **Failure-point table**: `results/tables/t1_failure_points.csv`, which records for each dimension \(n\) the first edge length \(L_{\text{fail}}\) (scanning from large to small) where \( \hat{k} < K_{\text{true}} \).
- **Figure**: `results/figs/t1_gap_curve.png` showing \(\hat{k}\) versus \(L\), faceted by \(n\), with dashed horizontal lines at \(K_{\text{true}}\) and a red dotted vertical line at \(L_{\text{fail}}\).

## Results (Quick View)

![](../results/figs/t1_gap_curve.png){width=92%}

```{r}
# Failure points per dimension
fail <- read.csv("../results/tables/t1_failure_points.csv")
fail

# Task 2 — Concentric Shells, Spectral Clustering, and the Gap Statistic

## Idea in one breath
We now switch to **concentric rings** in 2D. Each ring is a true cluster (so the true cluster count is the number of shells). We gradually shrink the overall scale via the **max radius** \(R\), from 10 down to 1, and run **spectral clustering** (epsilon-neighborhood graph, \(d_{\text{th}}=1.0\)) inside the Gap Statistic to estimate \(\hat{k}\).

## What to look for
- Dashed horizontal line = true cluster count (number of shells).  
- Red dotted vertical line = the first radius \(R_{\text{fail}}\) where we begin to **underestimate** \(\hat{k}<K_{\text{true}}\).  
- Red points = underestimates.

![](../results/figs/t2_gap_curve.png){width=92%}

```{r}
fail2 <- read.csv("../results/tables/t2_failure_points.csv")
fail2 EOF
